Thanks to all our community members and fans who sent us questions regarding our work. We received many questions and selected the most repeated ones.

MATRIX team will answer these 4 questions gaining the biggest concern which were raised on the live broadcast last Friday 4:00 pm Beijing time.

## ðŸš€QUESTIONS RECAPðŸš€

### 1.Do clusters play a part in consensus or is it just the delegated nodes? do they check that the work of the delegate is correct?(Node related Questions) 

### 2.Can you commit a date for main net token swap?


### 3.I was wondering if we could get a progress update on the development of Matrix. What are the next milestones to be achieved before the test-net launch and are we still on track to release the test-net in September 2018?

### 4.A detailed explanation of the delegate nodes (supernodes): How MATRIX can be more decentralized than EOS? How to choose delegate nodes and achieve consensus?


## ðŸš€ANSWERS OR EXPLANATIONSðŸš€
We hope the following information is what you are happy to know.


Matrix will launch test-net this September as per the original schedule. Thatâ€™s for sure.  Meanwhile, testing of token swap will also meet a kick off.  Each of our community members is welcome to participate in the testing for 3 months before the final go-live. Matrix Main Network will go online on 30th, December, 2018.

By the end of this month or maybe early next month, we will push our P2P codes designed based on Matrix network framework and a beta version of master node election algorithms to GITHUB. As for crypto part, we will also introduce a new enhanced version which is compatible with the current standard.


EN translation of the MATRIX masternode version is ongoing currently. Technical team will provide detailed explanation as regards the setup scheme as well as the configurations of miner/verification nodes, including but not limited to why and its benefits. Your valuable suggestions will be highly appreciated and accepted.


As for the progress update on the development, there will be a monthly report detailing what we achieved, where we are and what will be next. And our experts will take time to answer your questions each week.

You can find our current project plan here:

30th, June: we will bring you a Golang release supporting multi-machine interconnection and proof of concept;

30th, July: we will introduce a version which supports 32 SuperNodes running in LAN, in which the performance of one single machine can reach 1KTPS. Design proposal is as follows:

![](https://i.imgur.com/YUkXtwq.png)


The 50K TPS version currently in validation is based on a version with 3 cluster servers, which are 2 miner clusters and 1 verifier cluster. The front-end network uses FPGA version, without the ECC (Ellipse Curve Cryptography) validation. This is because we will use a standard PCIE CipherÂ Card for the final implementation.

As a matter of fact, the major bottleneck on the current design lies in how to achieve a steady network transfer and protocol processing. To combat this challenge, we have two new experts from HUAWEI joining us, who will be responsible for the design work based on Intel DPDK scheme. We will expect a model for proof  by the 30th, July. As you may know, this will eliminate the use of special hardware or FPGA, and a X86 processor can just make it.

MATRIX is designed to have 21 delegate nodes, which are the agents for transaction processing. Different from the EOSâ€™ supernodes, the delegate nodes of MATRIX are randomly selected in every given period. Such a design is to maintain decentralization and fairness in the sense that the probability of a node staying as a delegate for many times is sufficiently low. A node has to make a given amount of deposit before it can attend the selection process. The period for a selection is chosen as around 10 minutes.

![](https://i.imgur.com/1S9Tk7h.png)

The pseudo code for the random delegate selection algorithm is listed below. First, the qualified nodes are ordered with regard to their computing power. The nodes are then sequentially allocated to 32 clusters to maintain balanced computing power across clusters. Next, the algorithm iterates inside each cluster. Given a cluster, its nodes are initially assigned to 3-node groups in a random manner. The three nodes in each group will choose a winner node. The selection of the winner can be based on a random function, or a combination of computing power, communication bandwidth, network connectively, and other metrics. The winners will be randomly allocated to 3-node groups again in the next iteration and choose a winner again. This process repeats until there is only one left node, which will be the delegate nodes in the current cluster, while all other nodes are the voter nodes of the delegate. As there are initially have 32 nodes, we will have 21 to handle the transactions, and the remaining 11 nodes as the audition nodes to verify if the 21 delegates are working honestly.

MATRIX introduces a novel hybrid consensus mechanism. At the level of delegate nodes, the consensus is still PoW. It means that the 21 delegates will compete for reward. Such a competition is essential to motivate the miners. One the other hand, the delegate and its voters inside a cluster collaborate towards winning the reward. To raise its probability to win the PoW by employing more computing power, the delegate allocates the transactions to be verified and the mining work to the voters. Then all nodes work together in a concurrent fashion. The collaborative consensus mechanism leads to three major advantages. First, the redundant work among different nodes can be significantly reduced. Second, the transaction throughput and computing power for PoW can be dramatically raised. Third, the MATRIX blockchain can be organized as a massive platform to offer computing power. 

The mining algorithm of MATRIX no longer depends on the HASH function. Instead, it is based on the training of deep neural networks (DNNs) and/or the Markov Chain Monte Carlo algorithm for Bayesian reasoning. In other words, the mining of MATRIX is targeting the public welfare. MATRIX is equipped with portals to post machine learning jobs. The portals will accept problem formulation, DNN models, and training data. The 21 delegate nodes will fetch a posted job before the PoW computation. Then each delegate distributes its workload to its voters, which will train the model with asynchronous updating. In the case of training DNNs, every voter node will process a given number of training data and derive a local gradient, which is broadcasted to other nodes. These nodes update its gradient in the way similar to the federated learning algorithm. The delegate of the cluster first finishes the training will receive the award. 